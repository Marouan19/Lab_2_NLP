{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "103044c424e38b5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h1 style=\"text-align:center; font-size:200%;\">Lab 2</h1>\n",
    "<h1 style=\"text-align:center; font-size:150%;\">Bill Generation</h1>\n",
    "<h4 style=\"text-align:left;\">Performed by: DAGHMOUMI Marouan</h4>\n",
    "<h4 style=\"text-align:left;\">Supervised by: AACHAK Lotfi</h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cb248ecd3b07ca",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# *Part 1: Rule Based NLP and Regex:*"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "### 1.**Importation des biblio**\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "618e14ab53457cc3"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc00bc4656d18932",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T01:52:55.834366Z",
     "start_time": "2024-05-03T01:52:52.477643Z"
    }
   },
   "outputs": [],
   "source": [
    "from word2number import w2n\n",
    "from tabulate import tabulate\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "### 2.**Declaration**\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ecff14a4b66686a"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "numbers = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen', 'twenty', 'thirty', 'forty', 'fifty', 'sixty', 'seventy', 'eighty', 'ninety', 'hundred', 'thousand', 'million']\n",
    "pattern = r\"((?:\" + '|'.join(numbers) + r\"|\\d)(?:\\s(?:\" + '|'.join(numbers) + r\"|\\d|and))*)(.*?)(\\d+[\\.|\\,]?\\d*)\\b\\s*(\\$|dollar)\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T01:53:14.309020Z",
     "start_time": "2024-05-03T01:53:14.301087Z"
    }
   },
   "id": "65352d299b483935"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "text = \"I bought three Samsung smartphones 150 $ each, four kilos of fresh banana for 1,2 dollar a kilogram and one Hamburger with 4,5 dollar \""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T01:53:15.734886Z",
     "start_time": "2024-05-03T01:53:15.728665Z"
    }
   },
   "id": "8d9a2129d759b2f7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "### 3.**NLP pipline**\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5c16a31d4f673cd"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7f6833099c186a7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T02:40:29.407030Z",
     "start_time": "2024-05-03T02:40:28.407466Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load English tokenizer, tagger, parser, NER, and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Tokenize the text\n",
    "word_tokens = nlp(text)\n",
    "\n",
    "# Filter out tokens that are not stop words or adjectives\n",
    "filtered_tokens = [token.text for token in word_tokens if token.pos_ != \"ADJ\"]\n",
    "\n",
    "# Load English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Filter out stop words\n",
    "filtered_tokens = [token for token in filtered_tokens if token.lower() not in stop_words]\n",
    "filtered_tokens = ' '.join(filtered_tokens)\n",
    "\n",
    "# Define regex pattern to match weight units and words ending with \"gram\" or \"grams\"\n",
    "weight_units_regex = r'\\b(?:kg|kilos|lb|pound|[\\w]*(?:gram|grams))\\b'\n",
    "filtered_tokens = re.sub(weight_units_regex, '', filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.**Rule based**\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ac9f29e69849f28"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d82ee56223336a4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T02:40:37.773606Z",
     "start_time": "2024-05-03T02:40:37.767941Z"
    }
   },
   "outputs": [],
   "source": [
    "matches = re.finditer(pattern, filtered_tokens)\n",
    "\n",
    "# Initialize lists to store data for each column\n",
    "products = []\n",
    "quantities = []\n",
    "unit_prices = []\n",
    "total_prices = []\n",
    "\n",
    "# Process each match\n",
    "for match in matches:\n",
    "    quantity = match.group(1)\n",
    "    # Remove commas from the quantity string and convert it to a number\n",
    "    quantity = w2n.word_to_num(quantity.replace(',', '.'))\n",
    "    product = match.group(2)\n",
    "    price = float(match.group(3).replace(',', '.'))  # Remove commas from the price string\n",
    "    \n",
    "    # Calculate total price\n",
    "    total_price = quantity * price\n",
    "    \n",
    "    products.append(product)\n",
    "    quantities.append(quantity)\n",
    "    unit_prices.append(price)\n",
    "    total_prices.append(total_price)\n",
    "\n",
    "bill_data = list(zip(products, quantities, unit_prices, total_prices))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.**Resultat**\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86d704fe9572bf99"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[(' Samsung smartphones ', 3, 150.0, 450.0),\n ('  banana ', 4, 1.2, 4.8),\n (' Hamburger ', 1, 4.5, 4.5)]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bill_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T02:41:45.369249Z",
     "start_time": "2024-05-03T02:41:45.358765Z"
    }
   },
   "id": "32ec4942cef70503"
  },
  {
   "cell_type": "markdown",
   "id": "b16fa5a95e4b7058",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# *Part 2: word Embedding*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4a093aaa9bd2f4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1492527642f41a9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T02:55:35.857560Z",
     "start_time": "2024-05-03T02:55:35.842300Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "# Connect to MongoDB\n",
    "client = pymongo.MongoClient('localhost', 27017)\n",
    "db = client['Atelier1']\n",
    "collection = db['News_data']\n",
    "\n",
    "# Fetch content from MongoDB\n",
    "cursor = collection.find()\n",
    "content_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1da0e286c449d460",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T02:55:36.486862Z",
     "start_time": "2024-05-03T02:55:36.470114Z"
    }
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "# Assuming you have already defined the 'cursor' object\n",
    "for document in cursor:\n",
    "    if count >= 1:\n",
    "        break  # Exit the loop if we've processed two contents\n",
    "    content = document.get('content')\n",
    "    content_list.append(content)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "بعد يوم واحد من مطالبة منظمة العفو الدولية، السلطات الإسرائيلية بالإفراج عن السجين الفلسطيني وليد دقة البالغ من العمر 62 عاماً، أعلن نادي الأسير الفلسطيني عن وفاة وليد داخل السجن متأثراً بإصابته بمرض السرطان. وقالت منظمة العفو الدولية إن وليد دقة مصاب بـ\"مرض عضال\"، إذ شُخِّصت إصابته بسرطان النخاع الشوكي، والذي يُعَد من الحالات الطبية النادرة. ومنذ السابع من أكتوبر/تشرين الأول 2023، تعرَّض وليد دقة للتعذيب والإهانة وحُرِم من زيارات عائلته، إضافةً إلى تعرُّضه للإهمال الطبي، ونقل خلال الفترة الماضية إلى المستشفى مرتين بسبب تدهور حالته الصحية، بحسب منظمة العفو الدولية. ويقضي دقة حكماً بالسجن مدة 38 عاماً، بعد اتهامه بالمشاركة \"مع جماعة مسلحة اختطفت وقتلت جندياً إسرائيلياً عام 1984\" وهو موشيه تمام. وتقول منظمة العفو الدولية في تقرير صدر عنها العام الماضي إنه كان من المفترض انتهاء محكومية دقة في مارس/آذار 2023، لكن حكم عليه في محكمة عسكرية عام 2018 بالسجن عامين إضافيين بتهمة محاولة تهريب هواتف نقالة إلى سجناء فلسطينيين آخرين. وأعلنت هيئة شؤون الأسرى الفلسطينية وفاة السجين الفلسطيني وليد دقة في أحد المستشفيات الإسرائيلية، محملة إسرائيل المسؤولية عن وفاته. ونقلت وكالة فرانس برس عن رئيس هيئة شؤون الأسرى الفلسطينية قدورة فارس قوله إن \"استشهاد الأسير وليد يأتي  نتيجة سياسة الإهمال الطبي التي تمارسها سلطات الاحتلال ضد الأسرى\". وينحدر دقة من باقة الغربية، واعتقل في عام 1986 بتهمة خطف وقتل جندي اسرائيلي وحكم عليه بالإعدام، قبل تخفيف الحكم إلى السجن مدة 38 عاماً. وحمّلت حركة حماس في بيان صدر عنها عبر حسابها على تلغرام، إسرائيل ووزير أمنها القومي إيتمار بن غفير، مسؤولية وفاة وليد دقة، مشيرة إلى أن دقة عانى من مرض السرطان، ومن \"الإهمال الطبي المتعمّد والمفضي للقتل في سجون الاحتلال\". ونقلت صحيفة هآرتس الإسرائيلية أن دقة طلب الإفراج المبكر بسبب حالته الصحية، وأن مسؤول الصحة في مصلحة السجون الإسرائيلية \" قدّر أن أيامه معدودة وأن هناك خطراً حقيقياً على حياته\"، لكن الدولة رفضت استئناف الحكم، زاعمة أن مرضه \"لا يتناسب مع معايير الإفراج المبكر\" بحسب الصحيفة الإسرائيلية. وقال الباحث والأكاديمي الفلسطيني عبد الرحيم الشيخ في دراسة أجراها عن دقة ونشرت قبل نحو عامين عن تميز دقة في الكتابة وإتقانه للغة العبرية إضافة للغة العربية. ويروي الشيخ تجربة دقة في الإنجاب من زوجته الإعلامية سناء سلامة، إذ يقول إن ابنته ميلاد، جاءت إلى الحياة عبر \"نطفة محررة\"، ورفضت السلطات الإسرائيلية \"التماس تسجيل ابنته ميلاد التي جاءت إلى الحياة عبر نطفة محررة، أو تسجيلها مولودة  شرعية في سجلتها، ورفضت زيارتها لوالدها، إلى أن أجرت َ فحص الحمض النووي، وهي ابنة عام ونصف\". وعام 2019 بعد أن حاول لسنوات طويلة مع زوجته نيل قرار يسمح له بالإنجاب، تمكن من تهريب النطفة وزُرعت في رحم زوجته سناء سلامة، لترى ابنتهما ميلاد النور في عام 2020. وتنقل فرانس برس عن نادي الأسير الفلسطيني، وهو مؤسسة تعنى بمتابعة أوضاع المعتقلين الفلسطينيين، قوله إن 14 فلسطينياً توفوا في السجون الإسرائيلية منذ السابع من أكتوبر/تشرين الأول، كما أن عدد المعتقلين الفلسطينيين في السجون الإسرائيلية ارتفع بعد هذا التاريخ من 5 آلاف معتقل إلى أكثر من 9 آلاف.\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T11:09:14.787573Z",
     "start_time": "2024-05-03T11:09:14.779995Z"
    }
   },
   "id": "fc85dbd14b0cf60b"
  },
  {
   "cell_type": "markdown",
   "id": "81daad706af7016a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a5bf692c41792b1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T02:55:40.977060Z",
     "start_time": "2024-05-03T02:55:40.060701Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (1, 473), indices imply (1, 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 13\u001B[0m\n\u001B[1;32m     10\u001B[0m one_hot_encoded \u001B[38;5;241m=\u001B[39m encoder\u001B[38;5;241m.\u001B[39mfit_transform(tokenized_content)\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# Convert the sparse matrix to a DataFrame\u001B[39;00m\n\u001B[0;32m---> 13\u001B[0m one_hot_encoded_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(one_hot_encoded\u001B[38;5;241m.\u001B[39mtoarray(), columns\u001B[38;5;241m=\u001B[39mencoder\u001B[38;5;241m.\u001B[39mcategories_[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOne-hot Encoded DataFrame:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(one_hot_encoded_df)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:782\u001B[0m, in \u001B[0;36mDataFrame.__init__\u001B[0;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[1;32m    771\u001B[0m         mgr \u001B[38;5;241m=\u001B[39m dict_to_mgr(\n\u001B[1;32m    772\u001B[0m             \u001B[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001B[39;00m\n\u001B[1;32m    773\u001B[0m             \u001B[38;5;66;03m# attribute \"name\"\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    779\u001B[0m             copy\u001B[38;5;241m=\u001B[39m_copy,\n\u001B[1;32m    780\u001B[0m         )\n\u001B[1;32m    781\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 782\u001B[0m         mgr \u001B[38;5;241m=\u001B[39m ndarray_to_mgr(\n\u001B[1;32m    783\u001B[0m             data,\n\u001B[1;32m    784\u001B[0m             index,\n\u001B[1;32m    785\u001B[0m             columns,\n\u001B[1;32m    786\u001B[0m             dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[1;32m    787\u001B[0m             copy\u001B[38;5;241m=\u001B[39mcopy,\n\u001B[1;32m    788\u001B[0m             typ\u001B[38;5;241m=\u001B[39mmanager,\n\u001B[1;32m    789\u001B[0m         )\n\u001B[1;32m    791\u001B[0m \u001B[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001B[39;00m\n\u001B[1;32m    792\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m is_list_like(data):\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/internals/construction.py:336\u001B[0m, in \u001B[0;36mndarray_to_mgr\u001B[0;34m(values, index, columns, dtype, copy, typ)\u001B[0m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001B[39;00m\n\u001B[1;32m    332\u001B[0m index, columns \u001B[38;5;241m=\u001B[39m _get_axes(\n\u001B[1;32m    333\u001B[0m     values\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], values\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], index\u001B[38;5;241m=\u001B[39mindex, columns\u001B[38;5;241m=\u001B[39mcolumns\n\u001B[1;32m    334\u001B[0m )\n\u001B[0;32m--> 336\u001B[0m _check_values_indices_shape_match(values, index, columns)\n\u001B[1;32m    338\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m typ \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    339\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(values\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mtype, \u001B[38;5;28mstr\u001B[39m):\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/internals/construction.py:420\u001B[0m, in \u001B[0;36m_check_values_indices_shape_match\u001B[0;34m(values, index, columns)\u001B[0m\n\u001B[1;32m    418\u001B[0m passed \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m    419\u001B[0m implied \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mlen\u001B[39m(index), \u001B[38;5;28mlen\u001B[39m(columns))\n\u001B[0;32m--> 420\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShape of passed values is \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpassed\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, indices imply \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mimplied\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: Shape of passed values is (1, 473), indices imply (1, 1)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Tokenize the text content into words\n",
    "tokenized_content = [content.split() for content in content_list]\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit and transform the tokenized data\n",
    "one_hot_encoded = encoder.fit_transform(tokenized_content)\n",
    "\n",
    "# Convert the sparse matrix to a DataFrame\n",
    "one_hot_encoded_df = pd.DataFrame(one_hot_encoded.toarray(), columns=encoder.categories_[0])\n",
    "\n",
    "print(\"One-hot Encoded DataFrame:\")\n",
    "print(one_hot_encoded_df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176eb6655a86dab6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
